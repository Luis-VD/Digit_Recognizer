{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv',dtype = np.float32)\n",
    "test_data = pd.read_csv('data/test.csv',dtype = np.float32)\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0    1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2    1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3    4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0       0.0       0.0       0.0       0.0  \n",
       "1       0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0  \n",
       "3       0.0       0.0       0.0       0.0  \n",
       "4       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets_numpy = train_data.label.values\n",
    "features_numpy = train_data.loc[:,train_data.columns != \"label\"].values/255 # normalization\n",
    "\n",
    "output_features_numpy = test_data.values/255\n",
    "\n",
    "# train test split. Size of train data is 80% and size of test data is 20%. \n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42) \n",
    "\n",
    "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
    "outputFeatures = torch.from_numpy(output_features_numpy)\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = TensorDataset(featuresTrain,targetsTrain)\n",
    "test = TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# visualize one of the images in data set\n",
    "plt.imshow(features_numpy[10].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targets_numpy[10]))\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 8000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = TensorDataset(featuresTrain,targetsTrain)\n",
    "test = TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "# Create RNN\n",
    "input_dim = 28    # input dimension\n",
    "hidden_dim = 100  # hidden layer dimension\n",
    "layer_dim = 1     # number of hidden layers\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500  Loss: 1.0499409437179565  Accuracy: 60.119049072265625 %\n",
      "Iteration: 1000  Loss: 0.6731611490249634  Accuracy: 70.78571319580078 %\n",
      "Iteration: 1500  Loss: 0.5005505084991455  Accuracy: 85.92857360839844 %\n",
      "Iteration: 2000  Loss: 0.3836798071861267  Accuracy: 87.48809814453125 %\n",
      "Iteration: 2500  Loss: 0.22676363587379456  Accuracy: 88.71428680419922 %\n",
      "Iteration: 3000  Loss: 0.2091870754957199  Accuracy: 91.30952453613281 %\n",
      "Iteration: 3500  Loss: 0.2607764005661011  Accuracy: 90.51190185546875 %\n",
      "Iteration: 4000  Loss: 0.14784882962703705  Accuracy: 93.19047546386719 %\n",
      "Iteration: 4500  Loss: 0.38683655858039856  Accuracy: 93.73809814453125 %\n",
      "Iteration: 5000  Loss: 0.10807325690984726  Accuracy: 94.44047546386719 %\n",
      "Iteration: 5500  Loss: 0.18162769079208374  Accuracy: 92.47618865966797 %\n",
      "Iteration: 6000  Loss: 0.21499226987361908  Accuracy: 94.51190185546875 %\n",
      "Iteration: 6500  Loss: 0.23426206409931183  Accuracy: 91.3452377319336 %\n",
      "Iteration: 7000  Loss: 0.24582162499427795  Accuracy: 94.70237731933594 %\n",
      "Iteration: 7500  Loss: 0.1484343260526657  Accuracy: 95.14286041259766 %\n"
     ]
    }
   ],
   "source": [
    "seq_dim = 28  \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        train  = Variable(images.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "            \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 250 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if count % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(model(outputFeatures[0].view(-1, seq_dim, input_dim)).data, 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n"
     ]
    }
   ],
   "source": [
    "for i, row in sample_submission.iterrows():\n",
    "    outcome = model(outputFeatures[i].view(-1, seq_dim, input_dim)).data\n",
    "    sample_submission.iloc[i].Label = torch.max(outcome,1)[1].item()\n",
    "    \n",
    "print(len(sample_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head()\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
